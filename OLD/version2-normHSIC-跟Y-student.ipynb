{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f406cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf8\n",
    "\"\"\"\n",
    "# Author : Jianbai(Gus) Ye\n",
    "# created at Feb 2 2019\n",
    "# pytorch implementation of HSIC bottleneck method\n",
    "# reference : https://github.com/forin-xyz/Keras-HSIC-Bottleneck\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import unicode_literals\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "# from collections import Iterable\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd81593",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "device = \"cuda:1\"\n",
    "batch_size = 256\n",
    "train_loader, test_loader = load_data(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc3f57fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, inplane, outplane):\n",
    "        super(Block, self).__init__()\n",
    "        self.linear = nn.Linear(inplane, outplane)\n",
    "        self.bn = nn.BatchNorm1d(outplane, affine=False)\n",
    "        self.act = nn.GELU()\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.act(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "        \n",
    "class Test_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Test_model, self).__init__()\n",
    "        \n",
    "        self.units = [784, 256, 128, 128]\n",
    "#         self.module_list = [Block(self.units[i], self.units[i+1]).to(device) for i in range(len(self.units)-1)]\n",
    "        self.module_list = nn.ModuleList( [Block(self.units[i], self.units[i+1]) for i in range(len(self.units)-1)])\n",
    "        \n",
    "        self.f3 = nn.Dropout(p=0.2)\n",
    "        self.output_layer  = nn.Linear(self.units[-1], 10)        \n",
    "        self.act2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x = data\n",
    "        output = []\n",
    "        for module in self.module_list:\n",
    "            x_ = module(x.detach())\n",
    "            x = module(x)\n",
    "            output.append(x_)\n",
    "        x = self.f3(x)\n",
    "        x_ = self.act2(self.output_layer(x.detach()))\n",
    "        x = self.act2(self.output_layer(x))\n",
    "        output.append(x_)\n",
    "        return x, output\n",
    "    \n",
    "class HSICBottleneck:\n",
    "    def __init__(self, model, batch_size, lambda_0, sigma, multi_sigma=None,lr=0.01):\n",
    "        self.model      = model\n",
    "        self.batch_size = batch_size\n",
    "        self.lambda_0   = lambda_0\n",
    "        self.sigma      = sigma\n",
    "        self.extractor  = 'hsic'\n",
    "        self.last_linear = \"output_layer\"\n",
    "        self.lr         = lr\n",
    "        self.multi_sigma = multi_sigma\n",
    "        assert isinstance(self.multi_sigma, Iterable) if  multi_sigma is not None else True\n",
    "        \n",
    "        self.opt = optim.AdamW(self.model.parameters(), lr=0.001)\n",
    "#         self.opt = optim.SGD(self.model.parameters(), lr=0.001)\n",
    "        self.track_loss1 = []\n",
    "        self.track_loss2 = []\n",
    "        self.track_loss3 = []\n",
    "        \n",
    "        self.loss = \"CE\"\n",
    "        if self.loss == \"mse\":\n",
    "            self.output_criterion = nn.MSELoss()\n",
    "        elif self.loss == \"CE\":\n",
    "            self.output_criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def step(self, input_data, labels):\n",
    "        \n",
    "        one_hot_labels = F.one_hot(labels, num_classes=10)\n",
    "        if self.loss == \"mse\":\n",
    "            labels = F.one_hot(labels, num_classes=10).float()\n",
    "        \n",
    "        Kx  = kernel_matrix(input_data, self.sigma)\n",
    "        Ky = kernel_matrix(one_hot_labels, self.sigma)\n",
    "        \n",
    "        total_loss1 = 0.\n",
    "        total_loss2 = 0.\n",
    "        total_loss3 = 0.\n",
    "        y_pred, hidden_zs = self.model(input_data)\n",
    "        \n",
    "        kernel_list = list()\n",
    "        for num, feature in enumerate(hidden_zs):\n",
    "            kernel_list.append(kernel_student(feature, self.sigma))\n",
    "        \n",
    "        for num, feature in enumerate(kernel_list):\n",
    "            if num == (len(hidden_zs)-1): \n",
    "                loss1 = norm_HSIC(feature, kernel_list[num-1], self.batch_size, device)\n",
    "#                 loss2 = - self.lambda_0*norm_HSIC(feature, kernel_list[num+1], self.batch_size, device)\n",
    "                total_loss3 += self.output_criterion(feature, labels)\n",
    "            elif num == 0:\n",
    "                loss1 = norm_HSIC(feature, Kx, self.batch_size, device)\n",
    "                loss2 = - self.lambda_0*norm_HSIC(feature, Ky, self.batch_size, device)\n",
    "            else:\n",
    "                loss1 = norm_HSIC(feature, kernel_list[num-1], self.batch_size, device)\n",
    "                loss2 = - self.lambda_0*norm_HSIC(feature, Ky, self.batch_size, device)\n",
    "            total_loss1 += loss1\n",
    "            total_loss2 += loss2\n",
    "                \n",
    "#         total_loss = total_loss1 + total_loss2 + total_loss3\n",
    "        total_loss = total_loss2 + total_loss3\n",
    "        self.opt.zero_grad()\n",
    "        total_loss.backward()\n",
    "        self.opt.step()\n",
    "        \n",
    "#         self.track_loss1.append(total_loss1.item())\n",
    "        self.track_loss2.append(total_loss2.item())\n",
    "        self.track_loss3.append(total_loss3.item())\n",
    "                \n",
    "        return total_loss1.item(), total_loss2.item(), total_loss3.item()\n",
    "    \n",
    "    def tune_output(self, input_data, labels):\n",
    "        \n",
    "        if self.loss == \"mse\":\n",
    "            one_hot_labels = F.one_hot(labels, num_classes=10)\n",
    "            labels = F.one_hot(labels, num_classes=10).float()\n",
    "        \n",
    "        y_pred, hidden_zs = self.model(input_data)\n",
    "        total_loss = self.output_criterion(hidden_zs[-1], labels)\n",
    "        self.opt.zero_grad()\n",
    "        total_loss.backward()\n",
    "        self.opt.step()\n",
    "    \n",
    "        return total_loss.item()\n",
    "    \n",
    "def show_result():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        counts, correct, counts2, correct2 = 0, 0, 0, 0        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader): \n",
    "            output = hsic.model.forward(data.view(batch_size, -1).to(device))[0].cpu()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += (pred[:,0] == target).float().sum()\n",
    "            counts += len(pred)\n",
    "        for batch_idx, (data, target) in enumerate(test_loader): \n",
    "            output = hsic.model.forward(data.view(batch_size, -1).to(device))[0].cpu()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct2 += (pred[:,0] == target).float().sum()\n",
    "            counts2 += len(pred)\n",
    "        print(\"Training  ACC: {:.2f} \\t Testing ACC: {:.2f}\".format(correct/counts, correct2/counts2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e601ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Sigma 0.5 Lambda 100\n",
      "EPOCH 0\n",
      "Training  ACC: 0.95 \t Testing ACC: 0.94\n",
      "0.015, -0.055, 5.562, 0.520\n",
      "10.27\n",
      "EPOCH 10\n",
      "Training  ACC: 0.97 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.553, 0.106\n",
      "76.55\n",
      "EPOCH 20\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.552, 0.093\n",
      "76.60\n",
      "EPOCH 30\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.548, 0.085\n",
      "76.40\n",
      "EPOCH 40\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.551, 0.077\n",
      "76.73\n",
      "EPOCH 50\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.550, 0.077\n",
      "76.72\n",
      "EPOCH 60\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.551, 0.070\n",
      "76.71\n",
      "EPOCH 70\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.551, 0.071\n",
      "76.65\n",
      "EPOCH 80\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.553, 0.071\n",
      "76.86\n",
      "EPOCH 90\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.553, 0.068\n",
      "76.79\n",
      "===============================\n",
      "Sigma 0.5 Lambda 300\n",
      "EPOCH 0\n",
      "Training  ACC: 0.95 \t Testing ACC: 0.95\n",
      "0.015, -0.055, 5.558, 0.563\n",
      "9.79\n",
      "EPOCH 10\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.554, 0.104\n",
      "76.70\n",
      "EPOCH 20\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.550, 0.090\n",
      "76.84\n",
      "EPOCH 30\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.554, 0.089\n",
      "76.71\n",
      "EPOCH 40\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.552, 0.082\n",
      "76.80\n",
      "EPOCH 50\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.553, 0.084\n",
      "76.80\n",
      "EPOCH 60\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.553, 0.079\n",
      "76.71\n",
      "EPOCH 70\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.552, 0.079\n",
      "76.66\n",
      "EPOCH 80\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.553, 0.074\n",
      "76.69\n",
      "EPOCH 90\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.551, 0.070\n",
      "76.84\n",
      "===============================\n",
      "Sigma 0.5 Lambda 1000\n",
      "EPOCH 0\n",
      "Training  ACC: 0.95 \t Testing ACC: 0.94\n",
      "0.015, -0.055, 5.560, 0.555\n",
      "9.88\n",
      "EPOCH 10\n",
      "Training  ACC: 0.97 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.555, 0.110\n",
      "76.80\n",
      "EPOCH 20\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.554, 0.096\n",
      "76.71\n",
      "EPOCH 30\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.555, 0.089\n",
      "76.77\n",
      "EPOCH 40\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.550, 0.090\n",
      "76.81\n",
      "EPOCH 50\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.555, 0.081\n",
      "76.71\n",
      "EPOCH 60\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.555, 0.080\n",
      "76.77\n",
      "EPOCH 70\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.551, 0.077\n",
      "76.69\n",
      "EPOCH 80\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.550, 0.076\n",
      "76.87\n",
      "EPOCH 90\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.549, 0.073\n",
      "76.72\n",
      "===============================\n",
      "Sigma 0.5 Lambda 3000\n",
      "EPOCH 0\n",
      "Training  ACC: 0.94 \t Testing ACC: 0.94\n",
      "0.015, -0.055, 5.560, 0.535\n",
      "9.74\n",
      "EPOCH 10\n",
      "Training  ACC: 0.97 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.553, 0.109\n",
      "76.73\n",
      "EPOCH 20\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.555, 0.098\n",
      "76.71\n",
      "EPOCH 30\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.551, 0.089\n",
      "76.76\n",
      "EPOCH 40\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.552, 0.081\n",
      "76.64\n",
      "EPOCH 50\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.554, 0.078\n",
      "76.87\n",
      "EPOCH 60\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.549, 0.079\n",
      "76.81\n",
      "EPOCH 70\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.552, 0.075\n",
      "76.92\n",
      "EPOCH 80\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.554, 0.074\n",
      "76.88\n",
      "EPOCH 90\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.550, 0.075\n",
      "76.72\n",
      "===============================\n",
      "Sigma 1 Lambda 100\n",
      "EPOCH 0\n",
      "Training  ACC: 0.95 \t Testing ACC: 0.95\n",
      "0.015, -0.055, 5.559, 0.563\n",
      "9.82\n",
      "EPOCH 10\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.559, 0.096\n",
      "76.74\n",
      "EPOCH 20\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.556, 0.081\n",
      "76.74\n",
      "EPOCH 30\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.555, 0.077\n",
      "76.73\n",
      "EPOCH 40\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.98\n",
      "0.015, -0.055, 5.559, 0.069\n",
      "76.70\n",
      "EPOCH 50\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.553, 0.072\n",
      "76.93\n",
      "EPOCH 60\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.98\n",
      "0.015, -0.055, 5.556, 0.066\n",
      "76.69\n",
      "EPOCH 70\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.553, 0.065\n",
      "76.76\n",
      "EPOCH 80\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.552, 0.066\n",
      "76.71\n",
      "EPOCH 90\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.015, -0.055, 5.552, 0.061\n",
      "76.77\n",
      "===============================\n",
      "Sigma 1 Lambda 300\n",
      "EPOCH 0\n",
      "Training  ACC: 0.95 \t Testing ACC: 0.95\n",
      "0.015, -0.055, 5.562, 0.570\n",
      "9.84\n",
      "EPOCH 10\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.559, 0.098\n",
      "76.98\n",
      "EPOCH 20\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.555, 0.084\n",
      "76.80\n",
      "EPOCH 30\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.558, 0.079\n",
      "76.96\n",
      "EPOCH 40\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.557, 0.075\n",
      "79.61\n",
      "EPOCH 50\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.98\n",
      "0.015, -0.055, 5.556, 0.066\n",
      "79.63\n",
      "EPOCH 60\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.552, 0.067\n",
      "80.08\n",
      "EPOCH 70\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.555, 0.066\n",
      "79.92\n",
      "EPOCH 80\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.555, 0.065\n",
      "80.05\n",
      "EPOCH 90\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.015, -0.055, 5.553, 0.061\n",
      "79.91\n",
      "===============================\n",
      "Sigma 1 Lambda 1000\n",
      "EPOCH 0\n",
      "Training  ACC: 0.95 \t Testing ACC: 0.95\n",
      "0.015, -0.055, 5.561, 0.546\n",
      "10.34\n",
      "EPOCH 10\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.556, 0.102\n",
      "79.94\n",
      "EPOCH 20\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.558, 0.085\n",
      "79.60\n",
      "EPOCH 30\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.553, 0.079\n",
      "79.81\n",
      "EPOCH 40\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.558, 0.076\n",
      "80.17\n",
      "EPOCH 50\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.555, 0.069\n",
      "79.90\n",
      "EPOCH 60\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.98\n",
      "0.015, -0.055, 5.552, 0.067\n",
      "80.03\n",
      "EPOCH 70\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.551, 0.067\n",
      "80.03\n",
      "EPOCH 80\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.98\n",
      "0.015, -0.055, 5.554, 0.066\n",
      "80.01\n",
      "EPOCH 90\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.554, 0.062\n",
      "79.90\n",
      "===============================\n",
      "Sigma 1 Lambda 3000\n",
      "EPOCH 0\n",
      "Training  ACC: 0.95 \t Testing ACC: 0.95\n",
      "0.015, -0.055, 5.557, 0.547\n",
      "10.48\n",
      "EPOCH 10\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.560, 0.098\n",
      "80.09\n",
      "EPOCH 20\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.554, 0.082\n",
      "79.97\n",
      "EPOCH 30\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.555, 0.077\n",
      "80.06\n",
      "EPOCH 40\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.552, 0.074\n",
      "80.00\n",
      "EPOCH 50\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.553, 0.068\n",
      "79.82\n",
      "EPOCH 60\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.98\n",
      "0.015, -0.055, 5.552, 0.066\n",
      "79.64\n",
      "EPOCH 70\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.548, 0.062\n",
      "79.88\n",
      "EPOCH 80\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.97\n",
      "0.015, -0.055, 5.553, 0.061\n",
      "80.09\n",
      "EPOCH 90\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.015, -0.055, 5.554, 0.059\n",
      "80.04\n",
      "===============================\n",
      "Sigma 3 Lambda 100\n",
      "EPOCH 0\n",
      "Training  ACC: 0.95 \t Testing ACC: 0.95\n",
      "0.014, -0.055, 5.557, 0.589\n",
      "10.37\n",
      "EPOCH 10\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.566, 0.077\n",
      "80.33\n",
      "EPOCH 20\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.566, 0.067\n",
      "79.73\n",
      "EPOCH 30\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.558, 0.059\n",
      "80.06\n",
      "EPOCH 40\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.559, 0.058\n",
      "79.88\n",
      "EPOCH 50\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.556, 0.053\n",
      "80.04\n",
      "EPOCH 60\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.559, 0.054\n",
      "79.86\n",
      "EPOCH 70\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.558, 0.050\n",
      "80.43\n",
      "EPOCH 80\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.552, 0.050\n",
      "79.94\n",
      "EPOCH 90\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.557, 0.048\n",
      "79.85\n",
      "===============================\n",
      "Sigma 3 Lambda 300\n",
      "EPOCH 0\n",
      "Training  ACC: 0.96 \t Testing ACC: 0.95\n",
      "0.014, -0.055, 5.554, 0.603\n",
      "10.35\n",
      "EPOCH 10\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.564, 0.079\n",
      "80.15\n",
      "EPOCH 20\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.568, 0.064\n",
      "79.95\n",
      "EPOCH 30\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.557, 0.056\n",
      "80.04\n",
      "EPOCH 40\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.561, 0.056\n",
      "80.05\n",
      "EPOCH 50\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.561, 0.053\n",
      "80.09\n",
      "EPOCH 60\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.552, 0.050\n",
      "79.96\n",
      "EPOCH 70\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.558, 0.048\n",
      "80.05\n",
      "EPOCH 80\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.556, 0.047\n",
      "80.02\n",
      "EPOCH 90\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.556, 0.048\n",
      "80.01\n",
      "===============================\n",
      "Sigma 3 Lambda 1000\n",
      "EPOCH 0\n",
      "Training  ACC: 0.96 \t Testing ACC: 0.96\n",
      "0.014, -0.055, 5.557, 0.605\n",
      "10.43\n",
      "EPOCH 10\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.565, 0.074\n",
      "80.01\n",
      "EPOCH 20\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.565, 0.064\n",
      "79.83\n",
      "EPOCH 30\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.563, 0.061\n",
      "79.86\n",
      "EPOCH 40\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.565, 0.057\n",
      "79.89\n",
      "EPOCH 50\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.563, 0.053\n",
      "79.98\n",
      "EPOCH 60\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.552, 0.050\n",
      "79.86\n",
      "EPOCH 70\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.562, 0.050\n",
      "80.30\n",
      "EPOCH 80\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.557, 0.050\n",
      "79.97\n",
      "EPOCH 90\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.553, 0.047\n",
      "80.12\n",
      "===============================\n",
      "Sigma 3 Lambda 3000\n",
      "EPOCH 0\n",
      "Training  ACC: 0.96 \t Testing ACC: 0.95\n",
      "0.014, -0.055, 5.550, 0.586\n",
      "10.57\n",
      "EPOCH 10\n",
      "Training  ACC: 0.98 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.570, 0.076\n",
      "79.91\n",
      "EPOCH 20\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.565, 0.066\n",
      "80.07\n",
      "EPOCH 30\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.560, 0.059\n",
      "79.96\n",
      "EPOCH 40\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.558, 0.056\n",
      "79.96\n",
      "EPOCH 50\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.556, 0.054\n",
      "79.76\n",
      "EPOCH 60\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.556, 0.052\n",
      "80.09\n",
      "EPOCH 70\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.559, 0.050\n",
      "79.92\n",
      "EPOCH 80\n",
      "Training  ACC: 0.99 \t Testing ACC: 0.98\n",
      "0.014, -0.055, 5.553, 0.048\n",
      "80.07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for sigma in [0.5, 1, 3, 10]:\n",
    "    for lambda_0 in [100, 300, 1000, 3000]:\n",
    "        print(\"===============================\")\n",
    "        print(\"Sigma {} Lambda {}\".format(sigma, lambda_0))\n",
    "        \n",
    "        model = Test_model()\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        HSIC_epochs = 100\n",
    "#         lambda_0 = 500\n",
    "\n",
    "        hsic = HSICBottleneck(model, batch_size=batch_size, lambda_0=lambda_0, sigma=sigma)\n",
    "\n",
    "        start = time.time()\n",
    "        for epoch in range(HSIC_epochs):\n",
    "            model.train()\n",
    "\n",
    "            total_loss1, total_loss2, total_loss3, total_loss_tune = 0, 0, 0, 0\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                data = data.view(batch_size, -1)\n",
    "                loss1, loss2, loss3 = hsic.step(data.view(batch_size, -1).to(device), target.to(device))\n",
    "                total_loss_tune += hsic.tune_output(data.view(batch_size, -1).to(device), target.to(device))\n",
    "                total_loss1 += loss1\n",
    "                total_loss2 += loss2\n",
    "                total_loss3 += loss3\n",
    "            if epoch in range(0, 100, 10):\n",
    "                \n",
    "                print(\"EPOCH %d\" % epoch)\n",
    "                model.eval()\n",
    "                show_result()\n",
    "                sys.stdout.write(\"{:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(total_loss1/(batch_idx+1), \n",
    "                                                                         total_loss2/lambda_0*100/(batch_idx+1), \n",
    "                                                                         total_loss3/(batch_idx+1),\n",
    "                                                                         total_loss_tune/(batch_idx+1)))\n",
    "                sys.stdout.flush()\n",
    "                sys.stdout.write('\\n')\n",
    "                print(\"{:.2f}\".format(time.time()-start))\n",
    "                start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f456951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ce11c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "output, hidden = hsic.model(data.view(batch_size, -1).to(device))\n",
    "t = F.one_hot(target, num_classes=10).float()\n",
    "\n",
    "for i, z in enumerate(hidden):\n",
    "    print(i)\n",
    "    z_ = z.detach().cpu()\n",
    "    fig, axes = plt.subplots(1,3,figsize=(12,4))\n",
    "    axes[0].imshow(mean(kernel_matrix(data.view(batch_size, -1), 100)))\n",
    "    axes[1].imshow(mean(kernel_matrix(z_, 100)))\n",
    "    axes[2].imshow(mean(kernel_matrix(t, 100)))\n",
    "    plt.pause(0.1)\n",
    "    \n",
    "    fig, axes = plt.subplots(1,3,figsize=(12,4))\n",
    "    axes[0].imshow(mean(kernel_student(data.view(batch_size, -1), 100)))\n",
    "    axes[1].imshow(mean(kernel_student(z_, 100)))\n",
    "    axes[2].imshow(mean(kernel_student(t, 100)))\n",
    "    plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0d93ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c2aa70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT17",
   "language": "python",
   "name": "pt17"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
