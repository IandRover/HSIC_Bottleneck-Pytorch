{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84242367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf8\n",
    "\"\"\"\n",
    "# Author : Jianbai(Gus) Ye\n",
    "# created at Feb 2 2019\n",
    "# pytorch implementation of HSIC bottleneck method\n",
    "# reference : https://github.com/forin-xyz/Keras-HSIC-Bottleneck\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import unicode_literals\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "# from collections import Iterable\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f87c10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "batch_size = 128\n",
    "train_loader, test_loader = load_data(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a27710d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Extractor(nn.Module):\n",
    "    def __init__(self, model : nn.Module):\n",
    "        super(Extractor, self).__init__()\n",
    "        self.extractor_pre = 'hsic'\n",
    "        self.output_pre = 'output_layer'\n",
    "        self.all_layers = []\n",
    "        for name, layer in model.named_children():\n",
    "            setattr(self, name, layer)\n",
    "            self.all_layers.append(name)\n",
    "        self.all_layers = tuple(self.all_layers)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x = data\n",
    "        hidden = {}\n",
    "        for name in self.all_layers:\n",
    "            layer = getattr(self, name)\n",
    "            x_ = layer(x.detach())\n",
    "            x = layer(x)\n",
    "            if name.startswith(self.extractor_pre):\n",
    "                hidden[name] = x_\n",
    "            if name.startswith(self.output_pre):\n",
    "                hidden[name] = torch.sigmoid(x_)\n",
    "        return x, hidden\n",
    "\n",
    "class Test_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Test_model, self).__init__()\n",
    "        self.hsic1 = nn.Linear(784, 256)\n",
    "        self.hsic2 = nn.Linear(256, 256)\n",
    "        self.hsic3 = nn.Linear(256, 128)\n",
    "        self.hsic4 = nn.Linear(128, 128)\n",
    "        \n",
    "        self.f3 = nn.Dropout(p=0.2)\n",
    "        self.output_layer  = nn.Linear(128, 10)\n",
    "        \n",
    "        self.act1 = nn.GELU()\n",
    "        self.act2 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x = self.act1(self.hsic1(data))\n",
    "        x = self.f3(x)\n",
    "        x = self.act1(self.hsic2(x))\n",
    "        x = self.f3(x)\n",
    "        x = self.act1(self.hsic3(x))\n",
    "        x = self.f3(x)\n",
    "        x = self.act1(self.hsic4(x))\n",
    "        x = self.f3(x)\n",
    "        x = self.act2(self.output_layer(x))\n",
    "        return x\n",
    "    \n",
    "class HSICBottleneck:\n",
    "    def __init__(self, model, batch_size, lambda_0, sigma, multi_sigma=None,lr=0.01):\n",
    "        self.model      = Extractor(model)\n",
    "        self.batch_size = batch_size\n",
    "        self.lambda_0   = lambda_0\n",
    "        self.sigma      = sigma\n",
    "        self.extractor  = 'hsic'\n",
    "        self.last_linear = \"output_layer\"\n",
    "        self.lr         = lr\n",
    "        self.multi_sigma = multi_sigma\n",
    "        assert isinstance(self.multi_sigma, Iterable) if  multi_sigma is not None else True\n",
    "        \n",
    "        self.opt = optim.Adam(self.model.parameters(), lr=0.01)\n",
    "        self.track_loss1 = []\n",
    "        self.track_loss2 = []\n",
    "        self.track_loss3 = []\n",
    "        \n",
    "        self.output_criterion = nn.MSELoss()\n",
    "        \n",
    "    def step(self, input_data, labels):\n",
    "        \n",
    "        one_hot_labels = F.one_hot(labels, num_classes=10)\n",
    "        labels = F.one_hot(labels, num_classes=10).float()\n",
    "        \n",
    "        Kx  = kernel_matrix(input_data, self.sigma)\n",
    "        Ky = kernel_matrix(one_hot_labels, self.sigma)\n",
    "        \n",
    "        total_loss1 = 0.\n",
    "        total_loss2 = 0.\n",
    "        total_loss3 = 0.\n",
    "        y_pred, hidden_zs = self.model(input_data)\n",
    "        \n",
    "#         print(hidden_zs.keys())\n",
    "        for name, layer in self.model.named_children():\n",
    "            if self.extractor in name:\n",
    "                hidden_z = hidden_zs[name]\n",
    "                Kz = kernel_matrix(hidden_z, self.sigma)\n",
    "                loss1 = HSIC(Kz, Kx, self.batch_size) \n",
    "                loss2 = - self.lambda_0*HSIC(Kz,Ky, self.batch_size)\n",
    "                total_loss1 += loss1\n",
    "                total_loss2 += loss2\n",
    "            if self.last_linear in name:\n",
    "                hidden_z = hidden_zs[name]\n",
    "                total_loss3 += self.output_criterion(hidden_z, labels)\n",
    "                \n",
    "        total_loss = total_loss1 + total_loss2 + total_loss3\n",
    "        self.opt.zero_grad()\n",
    "        total_loss.backward()\n",
    "        self.opt.step()\n",
    "        \n",
    "        self.track_loss1.append(total_loss1.item())\n",
    "        self.track_loss2.append(total_loss2.item())\n",
    "        self.track_loss3.append(total_loss3.item())\n",
    "                \n",
    "        return total_loss1.item(), total_loss2.item(), total_loss3.item()\n",
    "    \n",
    "    \n",
    "    def tune_output(self, input_data, labels):\n",
    "        \n",
    "        one_hot_labels = F.one_hot(labels, num_classes=10)\n",
    "        labels = F.one_hot(labels, num_classes=10).float()\n",
    "        \n",
    "        total_loss3 = 0.\n",
    "        y_pred, hidden_zs = self.model(input_data)\n",
    "        \n",
    "        for name, layer in self.model.named_children():\n",
    "            if self.last_linear in name:\n",
    "                hidden_z = hidden_zs[name]\n",
    "                total_loss3 += self.output_criterion(hidden_z, labels)\n",
    "                \n",
    "        total_loss = total_loss3\n",
    "        self.opt.zero_grad()\n",
    "        total_loss.backward()\n",
    "        self.opt.step()\n",
    "    \n",
    "        self.track_loss3.append(total_loss3.item())\n",
    "        return total_loss3.item()\n",
    "    \n",
    "def show_result():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        counts, correct, counts2, correct2 = 0, 0, 0, 0        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader): \n",
    "            output = hsic.model.forward(data.view(batch_size, -1).to(device))[0].cpu()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += (pred[:,0] == target).float().sum()\n",
    "            counts += len(pred)\n",
    "        for batch_idx, (data, target) in enumerate(test_loader): \n",
    "            output = hsic.model.forward(data.view(batch_size, -1).to(device))[0].cpu()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct2 += (pred[:,0] == target).float().sum()\n",
    "            counts2 += len(pred)\n",
    "        print(\"Testing  ACC: {:.2f} \\t Training ACC: {:.2f}\".format(correct/counts, correct2/counts2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "052b397a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hsic1\n",
      "hsic2\n",
      "hsic3\n",
      "hsic4\n",
      "f3\n",
      "output_layer\n",
      "act1\n",
      "act2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d51a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "EPOCH 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-43a73315b35a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EPOCH %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mshow_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         sys.stdout.write(\"{:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(total_loss1/(batch_idx+1), \n\u001b[1;32m     26\u001b[0m                                                                  \u001b[0mtotal_loss2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlambda_0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-474ffae85f4e>\u001b[0m in \u001b[0;36mshow_result\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhsic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PT17/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PT17/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PT17/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PT17/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PT17/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PT17/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aaron/anaconda3/envs/PT17/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/aaron/anaconda3/envs/PT17/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aaron/anaconda3/envs/PT17/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/aaron/anaconda3/envs/PT17/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/aaron/anaconda3/envs/PT17/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/aaron/anaconda3/envs/PT17/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/aaron/anaconda3/envs/PT17/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/aaron/anaconda3/envs/PT17/lib/python3.7/multiprocessing/connection.py\", line 492, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/home/aaron/anaconda3/envs/PT17/lib/python3.7/multiprocessing/connection.py\", line 620, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "model = Test_model()\n",
    "model.to(device)\n",
    "model.train()\n",
    "HSIC_epochs = 100\n",
    "lambda_0 = 100\n",
    "\n",
    "hsic = HSICBottleneck(model, batch_size=batch_size, lambda_0=lambda_0, sigma=2.)\n",
    "\n",
    "for epoch in range(HSIC_epochs):\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    total_loss1, total_loss2, total_loss3, total_loss_tune = 0, 0, 0, 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.view(batch_size, -1)\n",
    "        loss1, loss2, loss3 = hsic.step(data.view(batch_size, -1).to(device), target.to(device))\n",
    "        total_loss1 += loss1\n",
    "        total_loss2 += loss2\n",
    "        total_loss3 += loss3\n",
    "    if epoch in range(0, 100, 10):\n",
    "        print(\"===============================\")\n",
    "        print(\"EPOCH %d\" % epoch)\n",
    "        model.eval()\n",
    "        show_result()\n",
    "        sys.stdout.write(\"{:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(total_loss1/(batch_idx+1), \n",
    "                                                                 total_loss2/lambda_0*100/(batch_idx+1), \n",
    "                                                                 total_loss3/(batch_idx+1),\n",
    "                                                                 total_loss_tune/(batch_idx+1)))\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write('\\n')\n",
    "        print(\"{:.2f}\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763fc548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a343dc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847114f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostTrained:\n",
    "    def __init__(self, model : nn.Module, criterion,lr=0.1):\n",
    "        parameters = []\n",
    "        model.train()\n",
    "        for name, layer in model.named_children():\n",
    "            if name == \"output_layer\":\n",
    "                for params in layer.parameters():\n",
    "                    parameters.append(params)\n",
    "            else:\n",
    "                for params in layer.parameters():\n",
    "                    params.requires_grad = False\n",
    "        self.opt   = optim.Adam(model.parameters(), lr=0.01)\n",
    "        self.model = model\n",
    "        self.lr    = lr\n",
    "        self.criterion = criterion\n",
    "#         summary(self.model, (batch_size, 784))\n",
    "\n",
    "    def step(self, input_data, labels):\n",
    "        output_data = self.model(input_data)\n",
    "        loss = self.criterion(output_data, labels)\n",
    "        self.opt.zero_grad()\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "        return loss.item()\n",
    "    \n",
    "def show_result_post():\n",
    "    post.model.eval()\n",
    "    with torch.no_grad():\n",
    "        counts = 0\n",
    "        correct = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader): \n",
    "            output = post.model.forward(data.view(batch_size, -1).to(device)).cpu()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += (pred[:,0] == target).float().sum()\n",
    "            counts += len(pred)\n",
    "        print(\"Training ACC: {:.3f}\".format(correct/counts))\n",
    "        \n",
    "        counts = 0\n",
    "        correct = 0        \n",
    "        for batch_idx, (data, target) in enumerate(test_loader): \n",
    "            output = post.model.forward(data.view(batch_size, -1).to(device)).cpu()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += (pred[:,0] == target).float().sum()\n",
    "            counts += len(pred)\n",
    "        print(\"Testing  ACC: {:.3f}\".format(correct/counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84925d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "POST_epochs = 10\n",
    "criterion = nn.MSELoss()\n",
    "post = PostTrained(model, criterion=criterion)\n",
    "post.model.to(device)\n",
    "for epoch in range(POST_epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        target = F.one_hot(target, num_classes=10).float()\n",
    "        loss = post.step(data.view(batch_size, -1).to(device), target.to(device))\n",
    "    if (epoch+1) % 5 == 0 or epoch == 0: \n",
    "        print(\"===============================\")\n",
    "        print(\"POST EPOCH %d\" % epoch)\n",
    "        show_result_post()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c63f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d729bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482ba1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT17",
   "language": "python",
   "name": "pt17"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
