{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd6151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf8\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, time, argparse\n",
    "\n",
    "from utils import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc660bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HSICBottleneck:\n",
    "    def __init__(self, args):\n",
    "        if args.model == \"MLP\":\n",
    "            self.model  = MLP(args)\n",
    "        if args.model == \"signMLP\":\n",
    "            self.model  = signMLP(args)\n",
    "        if args.model == \"CNN\":\n",
    "            self.model  = CNN(args)\n",
    "        if args.model == \"VGG\":\n",
    "            self.model  = VGG(args)\n",
    "        \n",
    "        self.model.to(device)\n",
    "        self.batch_size = args.batchsize\n",
    "        self.lambda_0   = args.lambda_\n",
    "        self.sigma      = args.sigma_\n",
    "        self.extractor  = 'hsic'\n",
    "        self.last_linear = \"output_layer\"\n",
    "        self.HSIC = compute_HSIC(args.HSIC)\n",
    "        self.kernel = compute_kernel()\n",
    "        self.kernel_x = args.kernel_x\n",
    "        self.kernel_h = args.kernel_h\n",
    "        self.kernel_y = args.kernel_y\n",
    "        self.forward = args.forward\n",
    "        \n",
    "        self.opt = optim.AdamW(self.model.parameters(), lr=0.001)\n",
    "#         self.opt = optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.01)\n",
    "        self.iter_loss1, self.iter_loss2, self.iter_loss3 = [], [], []\n",
    "        self.track_loss1, self.track_loss2, self.track_loss3 = [], [], []\n",
    "        \n",
    "        self.loss = args.loss\n",
    "        if self.loss == \"mse\": self.output_criterion = nn.MSELoss()\n",
    "        elif self.loss == \"CE\": self.output_criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def step(self, input_data, labels):\n",
    "        \n",
    "        labels_float = F.one_hot(labels, num_classes=10).float()\n",
    "        if self.forward == \"x\": Kx  = self.kernel(input_data, self.sigma, self.kernel_x)\n",
    "        Ky = self.kernel(labels_float, self.sigma, self.kernel_y)\n",
    "        \n",
    "        kernel_list = list()\n",
    "        y_pred, hidden_zs = self.model(input_data)\n",
    "        \n",
    "        loss_LI = 0.\n",
    "        for num, feature in enumerate(hidden_zs): \n",
    "            kernel_list.append(self.kernel(feature, self.sigma, self.kernel_h))\n",
    "            ## Testing new features.\n",
    "            if args.Latinb == 1:\n",
    "                if num == (len(hidden_zs)-1) or feature.size(2) >= 4: continue\n",
    "                loss_LI += spatial_contrast(feature, args)*args.Latinb_lambda\n",
    "        \n",
    "        total_loss1, total_loss2, total_loss3 = 0., 0., 0.\n",
    "        for num, feature in enumerate(kernel_list):\n",
    "            if num == (len(hidden_zs)-1): \n",
    "                if self.forward == \"h\": total_loss1 += self.HSIC(feature, kernel_list[num-1], self.batch_size, device)\n",
    "                elif self.forward == \"x\": total_loss1 += self.HSIC(feature, Kx, self.batch_size, device)\n",
    "                if self.loss == \"mse\": total_loss3 += self.output_criterion(hidden_zs[-1], labels_float)\n",
    "                elif self.loss == \"CE\": total_loss3 += self.output_criterion(hidden_zs[-1], labels)\n",
    "            elif num == 0:\n",
    "                if self.forward == \"x\": total_loss1 += self.HSIC(feature, Kx, self.batch_size, device)\n",
    "                total_loss2 += - self.lambda_0*self.HSIC(feature, Ky, self.batch_size, device)\n",
    "            else:\n",
    "                if self.forward == \"h\": total_loss1 += self.HSIC(feature, kernel_list[num-1], self.batch_size, device)\n",
    "                elif self.forward == \"x\": total_loss1 += self.HSIC(feature, Kx, self.batch_size, device)\n",
    "                total_loss2 += - self.lambda_0*self.HSIC(feature, Ky, self.batch_size, device)\n",
    "        \n",
    "        if self.forward == \"h\" or self.forward == \"x\": \n",
    "            total_loss = total_loss1 + total_loss2 + total_loss3 + loss_LI\n",
    "            self.iter_loss1.append(total_loss1.item())\n",
    "        if self.forward == \"n\": \n",
    "            total_loss = total_loss2 + total_loss3 + loss_LI\n",
    "            self.iter_loss1.append(-1)\n",
    "        self.opt.zero_grad()\n",
    "        total_loss.backward()\n",
    "        self.opt.step()\n",
    "                \n",
    "        self.iter_loss2.append(total_loss2.item())\n",
    "        self.iter_loss3.append(total_loss3.item())\n",
    "        \n",
    "    def update_loss(self):\n",
    "        self.track_loss1.append(np.mean(self.iter_loss1))\n",
    "        self.track_loss2.append(np.mean(self.iter_loss2))\n",
    "        self.track_loss3.append(np.mean(self.iter_loss3))\n",
    "        self.iter_loss1, self.iter_loss2, self.iter_loss3 = [], [], []\n",
    "    \n",
    "    def tune_output(self, input_data, labels):\n",
    "        self.model.train()\n",
    "        if self.loss == \"mse\":\n",
    "            one_hot_labels = F.one_hot(labels, num_classes=10)\n",
    "            labels = F.one_hot(labels, num_classes=10).float()\n",
    "        \n",
    "        y_pred, hidden_zs = self.model(input_data)\n",
    "        total_loss = self.output_criterion(hidden_zs[-1], labels)\n",
    "        self.opt.zero_grad()\n",
    "        total_loss.backward()\n",
    "        self.opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a278138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dataset', type=str, default=\"mnist\")\n",
    "    parser.add_argument('--model', type=str, default=\"VGG\")\n",
    "    parser.add_argument('--loss', type=str, default=\"CE\")\n",
    "    parser.add_argument('--BP', type=int, default=0)\n",
    "    parser.add_argument('--HSIC', type=str, default=\"nHSIC\")\n",
    "    parser.add_argument('--kernel_x', type=str, default=\"rbf\", choices=[\"rbf\", \"student\"])\n",
    "    parser.add_argument('--kernel_h', type=str, default=\"rbf\", choices=[\"rbf\", \"student\"])\n",
    "    parser.add_argument('--kernel_y', type=str, default=\"student\", choices=[\"rbf\", \"student\"])\n",
    "    parser.add_argument('--sigma_', type=int, default=10)\n",
    "    parser.add_argument('--lambda_', type=int, default=100)\n",
    "    parser.add_argument('--batchsize', type=int, default=128)\n",
    "    parser.add_argument('--device', type=int, default=1)\n",
    "    parser.add_argument('--bn_affine', type=int, default=1)\n",
    "    parser.add_argument('--forward', type=str, default=\"n\", choices=[\"x\", \"h\", \"n\"])\n",
    "    \n",
    "    # Testing.\n",
    "    parser.add_argument('--Latinb', type=int, default=0, choices=[0, 1])\n",
    "    parser.add_argument('--Latinb_lambda', type=float, default=1.)\n",
    "    parser.add_argument('--Latinb_type', type=str, default=\"f\", choices=[\"f\", \"n\"])\n",
    "        \n",
    "    args, _ = parser.parse_known_args()\n",
    "    filename = get_filename(args)\n",
    "    print(filename)\n",
    "    \n",
    "    torch.manual_seed(1)\n",
    "    device = \"cuda:{}\".format(args.device)\n",
    "    batch_size = args.batchsize\n",
    "    train_loader, test_loader = load_data(args)\n",
    "    \n",
    "    logs = list()\n",
    "    hsic = HSICBottleneck(args)\n",
    "    start = time.time()\n",
    "    get_loss = list()\n",
    "    for epoch in range(50):\n",
    "        hsic.model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data = data.view(args.batchsize, -1)\n",
    "            hsic.step(data.view(args.batchsize, -1).to(device), target.to(device))\n",
    "            hsic.tune_output(data.view(args.batchsize, -1).to(device), target.to(device))\n",
    "        if epoch % 2 == 0:\n",
    "            show_result(hsic, train_loader, test_loader, epoch, logs, device)\n",
    "            print(\"{:.2f}\".format(time.time()-start))\n",
    "            start = time.time()\n",
    "\n",
    "    txt_path = os.path.join(\"./results\", filename+\".csv\")\n",
    "    df = pd.DataFrame(logs)\n",
    "    df.to_csv(txt_path,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT17",
   "language": "python",
   "name": "pt17"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
